---
conference: Devoxx FR
title: A la découverte de la famille des modèles BERT
speaker: Alexia Audevart
date: 2025-04-17
video:
---
tags: #ia 

Fed Forward Neuronal Network
Les premiers réseaux de neurones

Les RNN Réseaux Récurrents de Neurones sont mieux pour traiter du texte
Plus longs à entrainés

Algo Word2Vec de Google pour créer des embeddings
(King - Man + Woman = Queen)
Similarité cosinus pour le rapprochement

Transformers (2017)
Mécanismes d'attention
Créent des embeddings avec du sens
Basée sur des encoders et des decoders
Modèles basées que sur du decoder -> Narural Language Generation
Modèles basés que sur des decoders -> Natural Language Understanding

BERT : Bidirectional Encdoer Representations for Transformers

Variants de BERT :
- RoBERTa
- DeBERTaV3
- DistilBERT : Moins de paramètres et presque même perfs
- FlauBERT
- CamemBERT
- CamemBERT-bio : Pour la biologie
- ModernBERT : Plus récent et sorti en déc 2024




